---
title: Projects
layout: single
permalink: /projects/
classes: wide
author_profile: false

feature_row:
  - image_path: /assets/images/projects/post-to-post-network.jpg
    alt: "Post-to-post network / GCN"
    title: "Misinformation Detection On Reddit Using Post-to-Post Networks"
    excerpt: >
      Posts are nodes; edges connect posts that share ≥20 commenters. Edge weights capture sentiment similarity from comment embeddings (cosine similarity). 
      Title text is embedded with **BERT** and reduced to 64-d features, then combined with graph structure in a **Graph Convolutional Network**.
      This post-to-post approach reached ~70% accuracy and outperformed a CNN baseline by leveraging *how* users interact with content, not just *what* the text says.
    url: /assets/docs/misinformation-detection-reddit.pdf
    btn_label: "Read paper (PDF)"
    btn_class: "btn--primary"

  - image_path: /assets/images/projects/fake-review.jpg
    alt: "Fake reviews detection visualization"
    title: "Detecting Fake Reviews Generated by Language Models"
    excerpt: >
      Combined **linguistic features** (TF-IDF/BoW, POS-derived authenticity & analytical thinking scores, LSTM, TF-Hub embeddings, cosine similarity across a reviewer's posts) 
      with **behavioral features** (bursty reviewer activity). 
      A stacked classifier (XGBoost + Naive Bayes + Random Forest) achieved 97.98% accuracy. Future work focuses on improving recall via more diverse LLM-generated samples and ensemble tuning.
    url: https://medium.com/@shaunak.divine/detecting-fake-reviews-generated-by-language-models-c3688d786718
    btn_label: "Read article"
    btn_class: "btn--primary"
---

A few things I’ve built and researched. Each card includes a quick summary, tech used, and links to the paper or write-up. Thanks for checking it out!

{% include feature_row %}
