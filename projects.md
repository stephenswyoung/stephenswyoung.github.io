---
title: Projects
layout: page
permalink: /projects/
---

# Projects

## Misinformation Detection On Reddit Using Post-to-Post Networks

A research project applying **Graph Convolutional Networks (GCNs)** to classify the credibility of URL shares in the r/Conservative subreddit.  

Rather than treating Reddit posts as isolated data points, we built a **post-to-post network** where:
- **Nodes** represent individual Reddit posts sharing a news URL.
- **Edges** connect two posts if they share at least 20 common commenters (ensuring connections are between posts that engage overlapping, active users and filtering out bot-driven links).
- **Edge weights** capture the **sentiment similarity** between shared commenters‚Äô reactions, computed via comment embeddings and cosine similarity scores. Higher weights indicate that the same users reacted in similar ways to both posts.

Text embeddings from **BERT** (`bert-base-nli-mean-tokens`) were combined with the network structure to train the GCN.  
Our model achieved **~70% classification accuracy**, outperforming a CNN baseline and showing that incorporating graph structure improves misinformation detection.  
The work details dataset preparation, graph construction, neural architecture, and experimental results, along with lessons learned about overfitting and data quality.

üìÑ [Read the full paper (PDF)](/assets/docs/misinformation-detection-reddit.pdf)

---

## Detecting Fake Reviews Generated by Language Models

A project addressing the growing threat of **AI-generated fake product reviews** on e-commerce platforms like Amazon.  
We developed an **ensemble classifier** that integrates both **linguistic** and **behavioral** features:

- **Linguistic approaches:**  
  - Preprocessing with tokenization, stopword removal, and lemmatization  
  - Vectorization (Bag of Words, TF-IDF)  
  - Naive Bayes, LSTM, pre-trained embeddings from TensorFlow Hub  
  - Part-of-speech (POS) analysis to derive ‚Äúauthenticity‚Äù and ‚Äúanalytical thinking‚Äù scores  
  - Cosine similarity between reviews from the same user  
  - Initial experiments with BERT transformers (high early accuracy but long training time)

- **Behavioral approaches:**  
  - Reviewer profiling  
  - Detecting bursts of reviews per user in short timeframes

The **final stacked model** (XGBoost + Naive Bayes + Random Forest) achieved:
- **Accuracy:** 97.98%  
- **Precision:** 0.8396  
- **Recall:** 0.3213  
- **F1 score:** 0.4648  

While highly accurate overall, the recall indicated difficulty in capturing all fake reviews, especially given the small and homogeneous set of LLM-generated reviews. Future work includes improving prompt diversity for generated review datasets and tuning ensemble integration.

üì∞ [Read the Medium article](https://medium.com/@shaunak.divine/detecting-fake-reviews-generated-by-language-models-c3688d786718)